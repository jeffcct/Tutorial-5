{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Exploratory data analytics on text data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = pd.read_csv(\"train.csv\")\n",
    "data_y = pd.read_csv(\"test.csv\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(data_X[\"Text\"])\n",
    "\n",
    "tfidDF = vectorizer.transform(data_X[\"Text\"])\n",
    "\n",
    "#number of articles and features\n",
    "num_articles = tfidDF.shape[0]\n",
    "num_features = tfidDF.shape[1]\n",
    "\n",
    "print(f\"Number of articles: {num_articles}\")\n",
    "print(f\"Number of extracted features: {num_features}\")\n",
    "\n",
    "#5 example articles\n",
    "fivearticles = data_X[\"Text\"].head(5)\n",
    "features = tfidDF[:5].toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "example_df = pd.DataFrame(features, columns=feature_names, index=fivearticles)\n",
    "\n",
    "print(example_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these articles, we peformed vectorisation using inverse document frequency as a way of tokenising the texts. From this, we observed 13518 unique words becoming our features from 428 articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "word_matrix = vectorizer.fit_transform(data_X[\"Text\"])\n",
    "word_hz = word_matrix.sum(axis=0).A1\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "term_freq_df = pd.DataFrame({'term': terms, 'frequency': word_hz})\n",
    "term_freq_df = term_freq_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "#plot 1\n",
    "plt.figure(figsize=(15, 8))\n",
    "top50 = term_freq_df.head(50)\n",
    "plt.bar(top50['term'], top50['frequency'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Terms')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top-50 Term Frequency Distribution Across Entire Dataset')\n",
    "plt.show()\n",
    "\n",
    "categories = data_X['Category'].unique()\n",
    "term_hz = {}\n",
    "\n",
    "for category in categories:\n",
    "    category_texts = data_X[data_X['Category'] == category]['Text']\n",
    "    category_word_matrix = vectorizer.transform(category_texts)\n",
    "    category_word_hz = category_word_matrix.sum(axis=0).A1\n",
    "    term_hz[category] = category_word_hz\n",
    "\n",
    "#plot 2&3\n",
    "fig, axes = plt.subplots(len(categories), 1, figsize=(15, 8 * len(categories)))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    term_freqDF = pd.DataFrame({'term': terms, 'frequency': term_hz[category]})\n",
    "    term_freqDF = term_freqDF.sort_values(by='frequency', ascending=False)\n",
    "    top50_terms = term_freqDF.head(50)\n",
    "    \n",
    "    axes[i].bar(top50_terms['term'], top50_terms['frequency'])\n",
    "    axes[i].set_xticks(range(len(top50_terms['term'])))\n",
    "    axes[i].set_xticklabels(top50_terms['term'], rotation=90)\n",
    "    axes[i].set_xlabel('Terms')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'Top-50 Term Frequency Distribution for Category: {category}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#plot 4\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_distribution = data_X['Category'].value_counts()\n",
    "category_distribution.plot(kind='bar')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.title('Category Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the above plots, we notice \"said' was mentioned the most frequently across all articles, surpassing the closest frequent word by over two times. The remaining top term frequencies seems quite consistent ranging from 600 down to 200. We also see \"said\" is most frequent in the category tech compared to entertainment. Overall, the data seems fairly balanced with similar number of articles for each category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Perform classification models (NB, kNN, SVM, NNs) to build article classifiers using the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft SVM\n",
    "y = data_X[\"Category\"]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(word_matrix, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# use cross validation to choose C\n",
    "c_param = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(SVC(kernel = \"linear\"), c_param, cv = 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_c = grid_search.best_params_['C']\n",
    "print(f'Best C parameter: {best_c}')\n",
    "\n",
    "# train final model with best c\n",
    "linear_svm = SVC(kernel = \"linear\", C = best_c)\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_linear = linear_svm.predict(X_valid)\n",
    "print('Soft-Margin Linear SVM:')\n",
    "print('Accuracy:', accuracy_score(y_valid, y_pred_linear))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_valid, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft SVM\n",
    "y = data_X[\"Category\"]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(word_matrix, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# use cross validation to choose C\n",
    "c_param = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(SVC(kernel = \"linear\"), c_param, cv = 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_c = grid_search.best_params_['C']\n",
    "print(f'Best C parameter: {best_c}')\n",
    "\n",
    "# train final model with best c\n",
    "linear_svm = SVC(kernel = \"linear\", C = best_c)\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_linear = linear_svm.predict(X_valid)\n",
    "print('Soft-Margin Linear SVM:')\n",
    "print('Accuracy:', accuracy_score(y_valid, y_pred_linear))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_valid, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Investigate the impact of multiple hyperparameters. Compare the classification quality across four classification models in terms of F1 measure. Learn to manage overfitting or underfitting situations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Report your answers for each question and summarize your insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
